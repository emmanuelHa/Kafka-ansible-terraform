# Install Packages
- name: Install the Kafka Connect Packages
  yum:
    name: "{{item}}-{{confluent.package_version}}"
    state: latest
  loop: "{{kafka_connect_packages}}"
  when: ansible_os_family == "RedHat"

- name: Install the Kafka Connect Packages
  apt:
    name: "{{item}}={{confluent.package_version}}"
    update_cache: yes
    force: yes
  loop: "{{kafka_connect_packages}}"
  when: ansible_os_family == "Debian"

# Configure environment
- name: Create Connect Distributed Group
  group:
    name: "{{kafka_connect.group}}"

- name: Create Connect Distributed User
  user:
    name: "{{kafka_connect.user}}"
    comment: "Connect Distributed User"
    system: yes
    group: "{{kafka_connect.group}}"

- name: Create Keytabs Directory
  file:
    path: "{{kerberos.keytab_dir}}"
    group: "{{kafka_connect.group}}"
    mode: '650'
    recurse: yes
  when: sasl_protocol == 'kerberos'

- name: Copy in Keytab File
  copy:
    src: "{{kafka_connect_kerberos_keytab_path}}"
    dest: "{{kerberos.keytab_dir}}/{{kafka_connect_kerberos_keytab_path | basename}}"
    mode: '600'
    owner: "{{kafka_connect.user}}"
    group: "{{kafka_connect.group}}"
  when: sasl_protocol == 'kerberos'
  notify:
    - restart connect distributed


- name: Download Lenses Kafka Connect Stream Reactor zip
  get_url:
    url: "https://github.com/lensesio/stream-reactor/releases/download/6.2.0/kafka-connect-aws-s3-6.2.0.zip"
    dest: "{{ lenses_jar_path }}"
    mode: 0755
    group: "{{kafka_connect.group}}"
    owner: "{{kafka_connect.user}}"
  when: lenses_enabled

- name: Unzip Lenses Kafka Connect Stream Reactor zip
  become: true
  become_user: "{{ kafka_connect.user }}"
  tags: lensesinstall
  shell: "unzip {{ lenses_jar_path }}/kafka-connect-aws-s3-6.2.0.zip"
  args:
    chdir: "{{ lenses_jar_path }}"
  register: kafka_connect.user
  when: lenses_enabled  

- name: Create Connect Distributed Config
  template:
    src: connect-distributed.properties.j2
    dest: "{{kafka_connect.config_file}}"
    mode: 0640
    owner: "{{kafka_connect.user}}"
    group: "{{kafka_connect.group}}"
  notify:
    - restart connect distributed

- name: Copy S3 connector source config file
  ansible.builtin.copy:
    src: ./connect-source-s3.properties
    dest: "{{kafka_connect.source_connector_config_file}}"
    mode: 0640
    owner: "{{kafka_connect.user}}"
    group: "{{kafka_connect.group}}"
  notify:
    - restart connect distributed

- name: Create Logs Directory
  file:
    path: "{{kafka_connect.appender_log_path}}"
    group: "{{kafka_connect.group}}"
    owner: "{{kafka_connect.user}}"
    mode: '764'
    recurse: yes

- name: Create Connect Distributed log4j Config
  template:
    src: connect_distributed_log4j.properties.j2
    dest: "{{kafka_connect.log4j_file}}"
    mode: 0640
    owner: "{{kafka_connect.user}}"
    group: "{{kafka_connect.group}}"
  notify:
    - restart connect distributed

- name: Create Service Override Directory
  file:
    path: "{{kafka_connect.systemd_override}}"
    owner: "{{kafka_connect.user}}"
    group: "{{kafka_connect.group}}"
    state: directory
    mode: 0640


    ## 
    ##  systemd-analyze verify /usr/lib/systemd/system/confluent-kafka-connect.service
    ## /etc/systemd/system/confluent-kafka-connect.service.d/override.conf
    ## /usr/bin/kafka-console-consumer --bootstrap-server private-ip:9092 --topic my-kafka-topic
    ## kafka-connect-s3-source-2.5.14.jar

- name: Write Service Overrides
  template:
    src: override.conf.j2
    dest: "{{kafka_connect.systemd_override}}/override.conf"
    mode: 0640
    owner: "{{kafka_connect.user}}"
    group: "{{kafka_connect.group}}"
  notify:
    - reload systemd
    - restart connect distributed

- name: Certs were Updated - Trigger Restart
  command: /bin/true
  notify: restart connect distributed
  when: certs_updated

- meta: flush_handlers

- name: Start Connect Service
  systemd:
    name: "{{kafka_connect.service_name}}"
    enabled: "{{kafka_connect.systemd.enabled}}"
    state: "{{kafka_connect.systemd.state}}"